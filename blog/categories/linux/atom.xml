<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: linux | Sibilia octopress blog]]></title>
  <link href="http://Sibilia.github.com/blog/categories/linux/atom.xml" rel="self"/>
  <link href="http://Sibilia.github.com/"/>
  <updated>2013-05-28T17:52:06+03:00</updated>
  <id>http://Sibilia.github.com/</id>
  <author>
    <name><![CDATA[Ilia Sibiryatkin]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[SSH трюки]]></title>
    <link href="http://Sibilia.github.com/blog/2013/05/28/ssh-trick/"/>
    <updated>2013-05-28T16:17:00+03:00</updated>
    <id>http://Sibilia.github.com/blog/2013/05/28/ssh-trick</id>
    <content type="html"><![CDATA[<h3>Проксирование соединения</h3>

<p>Допустим у вас есть необходимость подключаться к удалённому серверу host-end, к которому прямого доступа нет, и есть ssh доступ к серверу host-forw, с которого есть доступ к host-end. Тогда для удобства можно настроить проксирование ssh соединения. В результате, вместо последвательного подключения к host-forw -> host-end, можно будет подключаться сразу к host-end и соединение будет проксироваться через host-forw автоматически.
Для этого, нужно дбавить в конфиг ssh (~/.ssh/config):
<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ForwardAgent yes
</span><span class='line'>Host host-end&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;pre>&lt;code>HostName host-end
</span><span class='line'>Port 22
</span><span class='line'>User admin
</span><span class='line'>ProxyCommand ssh admin@host-forw nc %h %p
</span><span class='line'>Compression yes
</span><span class='line'>ForwardX11 no
</span><span class='line'>&lt;/code>&lt;/pre>
</span><span class='line'>
</span><span class='line'>&lt;p></span></code></pre></td></tr></table></div></figure></notextile></div>
Из примера видно, что можно все необходимые параметры прописать, а их кстати немало (man ssh_config).
Теперь для подключения достаточно набрать:
<code>
ssh host-end
</code></p>

<h3>Просмотр сетевого трафика с удалённого сервера</h3>

<p>На удалённом сервере зачастую есть сетевой сниффер tcpdump. Но снимать трафик на нём, затем переносить на свой комп для анализа в wireshark неудобно, намного проще направить поток с tcpdump сразу себе в wireshark:
<code>
ssh root@host-end -i eth0 -w - 'port !22' | wireshark -k -i -
</code></p>

<h3>Копирование файлов с удалённого сервера на другой, через локальный комп</h3>

<p>Необходимо перекинуть файлы с одного сервера на другой, но они друг друга не видят. Тогда можем перекинуть с локального, котой их обоих видит:
<code>
ssh root@host1 "tar -cf - /dir-copy" | ssh root@host2 "tar -xf - /dir-past/"
</code></p>

<h3>Запуск локального скрипта на удалённом сервере</h3>

<p><code>
ssh -T user@host &lt; script.sh
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NTP - синхронизация времени]]></title>
    <link href="http://Sibilia.github.com/blog/2013/04/11/ntp-sinkhronizatsiia-vriemieni/"/>
    <updated>2013-04-11T14:23:00+03:00</updated>
    <id>http://Sibilia.github.com/blog/2013/04/11/ntp-sinkhronizatsiia-vriemieni</id>
    <content type="html"><![CDATA[<p>Настроить синхронизацию времени в CentOS не сложно. Для этого нам понадобится NTP. Устанавливаем его:
<code>
yum install ntp
</code>
Далее разрешаем демону ntpd устанавливать аппаратное время. Для этого в файле /etc/sysconfig/ntpd прописываем строку SYNC_HWCLOCK=yes :
<code>
echo SYNC_HWCLOCK=yes &gt;&gt; /etc/sysconfig/ntpd
</code>
Запускаем демон ntpd и добавляем в автозагрузку:
<code>
/etc/init.d/ntpd start
chkconfig ntpd on
chkconfig --list ntpd
</code>
Через некоторое время можно проверить статус синхронизации:
```</p>

<h1>ntpstat</h1>

<p>synchronised to NTP server (86.57.151.12) at stratum 5
   time correct to within 570 ms
   polling server every 64 s
```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Синхронизация файлов с помощью Lsyncd и Unison]]></title>
    <link href="http://Sibilia.github.com/blog/2013/03/26/sinkhronizatsiia-failov-s-pomoshchiu-lsyncd-i-unison/"/>
    <updated>2013-03-26T13:52:00+03:00</updated>
    <id>http://Sibilia.github.com/blog/2013/03/26/sinkhronizatsiia-failov-s-pomoshchiu-lsyncd-i-unison</id>
    <content type="html"><![CDATA[<p>Для быстрой синхронизации файлов между двумя серверами, когда изменения могут появиться на любом из них, прекрасно подходит связка из <a href="https://code.google.com/p/lsyncd/">lsyncd</a> и <a href="http://www.cis.upenn.edu/~bcpierce/unison/">unison</a>.</p>

<p>Lsyncd - это демон который слушает дерево каталогов и выполняет синхронизацию при событии (inotify или fsevents) на нём. Синхронизировать он может с помощью rsync или любым другим способом, который можно прописать у него в настройках в виде скрипта на Lua.</p>

<p>Unison позволяет синхронизировать файлы между серверами (или локально два различных каталога). В отличие от rsync он позволяет синхронизировать файлы одновременно в обе стороны. В качестве транспорта при синхронизации может быть использован ssh.
Пример буду приводить для CentOS/RedHat, для .deb систем отличия в мелочах. Начнём с установки:</p>

<!-- more -->


<p><code>
yum install lsyncd unison
</code>
Далее правим конфигурационный файл lsyncd: /etc/lsyncd.conf
<div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>settings <span class="o">{</span>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    <span class="nv">logfile</span>         <span class="o">=</span> <span class="s2">&quot;/mnt/lsynced.lsync.log&quot;</span>,
</span><span class='line'>    <span class="nv">statusFile</span>      <span class="o">=</span> <span class="s2">&quot;/mnt/lsynced.lsync.status&quot;</span>,
</span><span class='line'>    <span class="nv">statusInterval</span>  <span class="o">=</span> 10,
</span><span class='line'>    <span class="nv">maxDelays</span>       <span class="o">=</span> 3,
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;<span class="o">}</span>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;runUnison <span class="o">=</span> <span class="o">[[</span>/usr/bin/unison -retry 5 -owner -group -batch /mnt/lsynced ssh://node2//mnt/lsynced<span class="o">]]</span>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;runbash <span class="o">=</span> <span class="o">{</span>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    <span class="nv">onCreate</span> <span class="o">=</span> runUnison,
</span><span class='line'>    <span class="nv">onDelete</span> <span class="o">=</span> runUnison,
</span><span class='line'>    <span class="nv">onModify</span> <span class="o">=</span> runUnison,
</span><span class='line'>    <span class="nv">onMove</span> <span class="o">=</span> runUnison,
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;<span class="o">}</span>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;sync <span class="o">{</span>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    runbash,
</span><span class='line'>    <span class="nv">maxProcesses</span> <span class="o">=</span> 1,
</span><span class='line'>    <span class="nv">delay</span> <span class="o">=</span> 3,
</span><span class='line'>    <span class="nb">source</span> <span class="o">=</span> <span class="s2">&quot;/mnt/lsynced&quot;</span>,
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;<span class="o">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
На втором сервере меняем имя хоста в строке вызова unison. Проверить можно запустив lsyncd в режиме nodaemon (или без этой опции и читать логи):
<code>
lsyncd -nodaemon /etc/lsyncd.conf
</code>
Если всё отлично завершаем и переходим к настройке запуска lsyncd под corosync.
Тут есть два способа: использовать lsb ресурс corosync или написать свой ресурс агент. Я рассмотрю первый вариант. Для второго у меня на github лежит ресурс агент, но я его ещё не до конца протестировал.</p>

<h3>Corosync lsyncd LSB ресурс.</h3>

<p>Нам понадобится скрипт lsyncd daemon: /etc/init.d/lsyncd. Он должен входить в пакет lsyncd начиная с версии 2.1. Учитывая один момент в нём:
<div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">LSYNCD_OPTIONS</span><span class="o">=</span><span class="s2">&quot;-pidfile /var/run/lsyncd.pid /etc/lsyncd.conf&quot;</span>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;if <span class="o">[</span> -e /etc/sysconfig/lsyncd <span class="o">]</span>; <span class="k">then</span>
</span><span class='line'>  . /etc/sysconfig/lsyncd
</span><span class='line'><span class="k">fi</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
нам обязательно надо прописать опции запуска в файле /etc/sysconfig/lsyncd:
<div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">LSYNCD_OPTIONS</span><span class="o">=</span><span class="s2">&quot;-log scarce /etc/lsyncd.conf&quot;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
Опция "-log scarce" уменьшает уровень логирования.
Теперь осталось добавить lsyncd в конфигурацию corosync:
<code>
crm configure primitive lsyncd-node1 lsb:lsyncd op monitor interval="5" meta target-role="Started"
crm configure location loc-lsyncd-on-node1 lsyncd-node1 inf: node1
</code>
На втором сервере делаем соответствующие поправки.
Вот в принципе и всё. Данное решение синхронизации хорошо себя показало на высоких нагрузках. Если есть вопросы, я постораюсь помочь.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Установка crm shell в Pacemaker]]></title>
    <link href="http://Sibilia.github.com/blog/2013/03/14/ustanovka-crm-shell-v-pacemaker/"/>
    <updated>2013-03-14T14:36:00+03:00</updated>
    <id>http://Sibilia.github.com/blog/2013/03/14/ustanovka-crm-shell-v-pacemaker</id>
    <content type="html"><![CDATA[<p>В начале марта в проекте Pacemaker произошли некоторые изменения, в частности был вырезан crm shell начиная с версии pacemaker-1.1.7.
<blockquote><p>Since late-April, the crm shell is no longer included in the Pacemaker source tree. This change was made at the author's request as it is now maintained as a separate project.</p><footer><strong>ClusterLabs</strong> <cite><a href='https://github.com/ClusterLabs/pacemaker#important-information-about-the-crm-shell'>Important Information About the Crm Shell</a></cite></footer></blockquote></p>

<!-- more -->


<p>Это довольно печально, так как crm shell очень удобный инструмент для ручного управления кластером. Для его добавления необходимо доустановить пакеты "crmsh" и "pssh". Скачать их можно с репозитория <a href="http://download.opensuse.org/repositories/network:/ha-clustering/">crm shell</a>.
Для CentOS 6 x86-64 достаточно следующее:
<code>
yum install pacemaker corosync
cd /tmp
wget http://download.opensuse.org/repositories/network:/ha-clustering/CentOS_CentOS-6/x86_64/crmsh-1.2.5-55.2.x86_64.rpm
wget http://download.opensuse.org/repositories/network:/ha-clustering/CentOS_CentOS-6/x86_64/pssh-2.3.1-15.1.x86_64.rpm
yum install ./crmsh*.rpm ./pssh*.rpm
</code>
На данный момент пакетов crmsh и pssh отсутствуют в официальных репозитариях RedHat/CentOS и в EPEL. Быть может в скором времени их туда добавят, или clusterlabs уладят совместимость.</p>

<h3>P.S.</h3>

<p>Вот кстати мой скрипт для отчистки failcount в выводе crm_mon -fnr. Это порой необходимо для востановления кластера после сбоя и обнуления счётчиков.
<div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span> (corosync_clear)</span> <a href='/downloads/code/corosync_clear'>download</a></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c">#!/bin/bash</span>
</span><span class='line'><span class="c"># Если значение failcount=1000000 у ресурса, то сбрасывается его состояние (crm resource cleanup &lt;res&gt;).</span>
</span><span class='line'><span class="c">#</span>
</span><span class='line'><span class="c"># Author: Ilia Sibiryatkin &lt;Sibvilian@gmail.com&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="nv">NODE</span><span class="o">=</span><span class="sb">`</span>crm_node -l |cut -d<span class="s1">&#39; &#39;</span> -f 2<span class="sb">`</span>
</span><span class='line'>
</span><span class='line'><span class="k">for </span>STR in <span class="k">$(</span>crm_mon -f1 | grep fail-count| awk <span class="s1">&#39;{ print $1 &quot;@&quot; $3 }&#39;</span><span class="k">)</span> ; <span class="k">do</span>
</span><span class='line'><span class="k">	</span><span class="nv">RES</span><span class="o">=</span><span class="k">$(</span><span class="nb">echo</span> <span class="nv">$STR</span> |awk <span class="s1">&#39;BEGIN {FS=&quot;@&quot;}{print (substr($1,0,length($1)-1))}&#39;</span><span class="k">)</span>
</span><span class='line'>        <span class="nv">FAIL</span><span class="o">=</span><span class="k">$(</span><span class="nb">echo</span> <span class="nv">$STR</span> |awk <span class="s1">&#39;BEGIN {FS=&quot;@&quot;}{print (substr($2,12,length($2)))}&#39;</span><span class="k">)</span>
</span><span class='line'>
</span><span class='line'>        <span class="k">if</span> <span class="o">[[</span> <span class="nv">$FAIL</span> <span class="o">==</span> 1000000 <span class="o">]]</span>; <span class="k">then</span>
</span><span class='line'><span class="k">                </span><span class="nb">echo</span> <span class="s2">&quot;cleanup $RES&quot;</span>
</span><span class='line'>                crm resource cleanup <span class="nv">$RES</span>
</span><span class='line'>        <span class="k">else</span>
</span><span class='line'><span class="k">                </span><span class="nb">echo</span> <span class="s2">&quot;clear fail-count $RES&quot;</span>
</span><span class='line'>                <span class="k">for </span>i in <span class="nv">$NODE</span> ; <span class="k">do</span>
</span><span class='line'><span class="k">                        </span>crm resource failcount <span class="nv">$RES</span> delete <span class="nv">$i</span>
</span><span class='line'>                <span class="k">done </span>
</span><span class='line'><span class="k">        fi</span>
</span><span class='line'><span class="k">done</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Перенаправление http]]></title>
    <link href="http://Sibilia.github.com/blog/2013/03/04/pierienapravlieniie-http/"/>
    <updated>2013-03-04T13:53:00+03:00</updated>
    <id>http://Sibilia.github.com/blog/2013/03/04/pierienapravlieniie-http</id>
    <content type="html"><![CDATA[<p>Возникла необходимость по наступлению определённого события временно перенаправлять http соединения на другой порт, где слушает nginx с заглушкой. Это легко можно сделать с помошью парочки правил в iptables. Приведу несколько основных моментов из bash скрипта.
Нам нужны две таблицы в новой цепочке: "nat" для непосредственно перенаправления и "filter" для сброса активных сессий. Фильтровать активные сессии необходимо потому, что в таблицу "nat", цепочки PREROUTING, поподают лишь tcp соединения с состоянием NEW. Активные tcp соединения живут примерно 2-3 минуты. Если это не критично, то можно обойтись без их фильтрации. Для этого просто не добавляем все правила в которых указана таблица "filter".
Для начала создадим новую цепочку. Это удобно тем что её можно очистить полностью, когда необходимо вернуть всё к изначальному состоянию.
<code>
iptables -t nat -N HTTP_REDIR
iptables -t filter -N HTTP_REDIR
</code></p>

<!-- more -->


<p>Теперь создадим два правила в цепочках PREROUTING и INPUT в которых будем направлять tcp в нашу цепочку. Эти правила не будут удаляться.
<code>
iptables -t nat -I PREROUTING -p tcp -j HTTP_REDIR
iptables -t filter -I INPUT -p tcp -j HTTP_REDIR
</code>
Теперь, если нам необходимо включить перенаправление, то добавляем правила в нашу цепочку:
<code>
iptables -t nat -A HTTP_REDIR -p tcp --dport 80 -j REDIRECT --to-port 20302
iptables -t filter -A HTTP_REDIR -p tcp --dport 80 -j REJECT --reject-with tcp-reset
</code>
Если необходимо перенаправлять к примеру ещё и https то можно вместо "--dport 80" указать "-m multiport --dports 80,443"
Чтобы убрать перенаправление, просто чистим нашу цепочку.
<code>
iptables -t nat -F HTTP_REDIR
iptables -t filter -F HTTP_REDIR
</code>
Вот в принципе и всё, за всеми подробностями идём в маны iptables, написано там всё очень подробно.</p>

<h4>P.S.</h4>

<p>Нашел более удобный способ сброса активный tcp соединений - conntrack.
Пакет называется по разному, в Debian вроде просто conntrack, в CentOS/RedHat conntrack-tool.
После установки, у нас появляется возможность удобно посмотреть активные соединения и их статус:
<code>
conntrack -L -p tcp --dport 80
</code>
Так же удобно их разом очистить:
<code>
conntrack -D -p tcp --dport 80
</code>
Фильтровать он по multiport не умеет. Суть заключается в том, что просто чистится в ядре таблица соединений tcp по определённому порту. Входящий пакет после этого со статусом не NEW не находится в таблице и сбрасывается с tcp-reset.
В таком случае нет нужды использовать таблицу filter.</p>
]]></content>
  </entry>
  
</feed>
